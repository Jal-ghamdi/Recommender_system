# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kuuvUKGvDWtq0NX4AL8Sm_trM5JIrDsI
"""

!unzip /content/ratings.csv.zip

import pandas as pd
books = pd.read_csv('books.csv', sep=";", on_bad_lines='skip' ,encoding='latin-1')
users = pd.read_csv('users.csv', sep=";",on_bad_lines='skip', encoding='latin-1')
ratings = pd.read_csv('ratings.csv', sep=";", on_bad_lines='skip',encoding='latin-1')

books.head()

books.columns

books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher',
       'Image-URL-L']]
books

books.rename(columns={'Book-Title':'title', 'Book-Author':'author', 'Year-Of-Publication':'year', 'Publisher':'publisher','Image-URL-L':'img_url'}, inplace=True)

books.head(1)

users.head(3)

ratings.head(3)

print(books.shape)
print(users.shape)
print(ratings.shape)

ratings.rename(columns={'User-ID':'user_id', 'Book-Rating':'rating'}, inplace=True)

ratings.head(2)

users.rename(columns={'User-ID':'user_id', 'Location':'location', 'Age':'age'}, inplace=True)
users.head(2)

ratings['user_id'].value_counts()

ratings['user_id'].unique().shape

x = ratings['user_id'].value_counts() > 200
x[x]

y = x[x].index

y

ratings=ratings[ratings['user_id'].isin(y)]
ratings.head()

rating_with_books=ratings.merge(books,on='ISBN')

rating_with_books.head(5)

num_rating=rating_with_books.groupby('title')['rating'].count().reset_index()
num_rating.head()

num_rating.rename(columns={'rating':'num_of_rating'}, inplace=True)
num_rating.head()

rating_with_books.head()

final_rating=rating_with_books.merge(num_rating,on='title')
final_rating.head()

final_rating=final_rating[final_rating['num_of_rating']>=50]
final_rating.head()

final_rating.sample()

final_rating.drop_duplicates(['title','user_id'],inplace=True)
final_rating.shape

book_pivot = final_rating.pivot_table(columns='user_id',index='title',values='rating')
book_pivot

book_pivot.fillna(0,inplace=True)
book_pivot

from scipy.sparse import csr_matrix
book_sparse = csr_matrix(book_pivot)

from sklearn.neighbors import NearestNeighbors
model = NearestNeighbors(algorithm='brute')
model.fit(book_sparse)

distance, suggestion=model.kneighbors(book_pivot.iloc[237,:].values.reshape(1,-1),n_neighbors=6)

book_pivot.iloc[237,:].values.reshape(1,-1)

distance

suggestion

book_pivot.iloc[240,:]

for i in range(len(suggestion)):
  print(book_pivot.index[suggestion[i]])

book_name=book_pivot.index
book_name

import pickle
pickle.dump(model,open('model.pkl','wb'))
pickle.dump(book_name,open('book_name.pkl','wb'))
pickle.dump(final_rating,open('final_rating.pkl','wb'))
pickle.dump(book_pivot,open('book_pivot.pkl','wb'))

import numpy as np
np.where(book_pivot.index=='1984')[0][0]

def recommend_book(book_name):
  book_id=np.where(book_pivot.index==book_name)[0][0]
  distance, suggestion=model.kneighbors(book_pivot.iloc[book_id,:].values.reshape(1,-1),n_neighbors=6)
  for i in range(len(suggestion)):
    books=book_pivot.index[suggestion[i]]
    for j in books:
      print(j)

recommend_book('A Cry In The Night')

